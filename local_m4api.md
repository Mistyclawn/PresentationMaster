# Ollama API ì‚¬ìš© ê°€ì´ë“œ


## ğŸ“‹ ëª©ì°¨
1. [ê¸°ë³¸ ì„¤ì •](#ê¸°ë³¸-ì„¤ì •)
2. [ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸](#ì£¼ìš”-api-ì—”ë“œí¬ì¸íŠ¸)
3. [Python ì‚¬ìš© ì˜ˆì œ](#python-ì‚¬ìš©-ì˜ˆì œ)
4. [cURL ì‚¬ìš© ì˜ˆì œ](#curl-ì‚¬ìš©-ì˜ˆì œ)
5. [ê³ ê¸‰ ì˜µì…˜](#ê³ ê¸‰-ì˜µì…˜)


---


## ğŸš€ ê¸°ë³¸ ì„¤ì •


### ì„œë²„ ì‹¤í–‰
```bash
python run_ollama.py
```


### ë„¤íŠ¸ì›Œí¬ ì„¤ì •
ë‹¤ë¥¸ PCì—ì„œ ì ‘ê·¼í•˜ë ¤ë©´ ì„œë²„ì˜ IP ì£¼ì†Œë¥¼ ì‚¬ìš©:
```bash
# ì„œë²„ ì‹¤í–‰ ì‹œ í‘œì‹œëœ IP ì£¼ì†Œ í™•ì¸
# ì˜ˆ: http://192.168.1.100:11434
```


---


## ğŸ“¡ ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸


### 1. `/api/generate` - í…ìŠ¤íŠ¸ ìƒì„±
ê¸°ë³¸ì ì¸ í”„ë¡¬í”„íŠ¸ â†’ ì‘ë‹µ ìƒì„±


**ìš”ì²­:**
```json
{
  "model": "gpt-oss:20b",
  "prompt": "Hello, how are you?",
  "stream": false
}
```


**ì‘ë‹µ:**
```json
{
  "model": "llama2",
  "created_at": "2025-12-31T12:00:00Z",
  "response": "I'm doing well, thank you!",
  "done": true
}
```


### 2. `/api/chat` - ì±„íŒ… ëŒ€í™”
ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€


**ìš”ì²­:**
```json
{
  "model": "llama2",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is Python?"}
  ],
  "stream": false
}
```


**ì‘ë‹µ:**
```json
{
  "message": {
    "role": "assistant",
    "content": "Python is a high-level programming language..."
  },
  "done": true
}
```


### 3. `/api/tags` - ëª¨ë¸ ëª©ë¡
ì„¤ì¹˜ëœ ëª¨ë¸ ì¡°íšŒ


**ìš”ì²­:**
```bash
GET /api/tags
```


**ì‘ë‹µ:**
```json
{
  "models": [
    {
      "name": "llama2:latest",
      "size": 3826793677,
      "modified_at": "2025-12-31T12:00:00Z"
    }
  ]
}
```


### 4. `/api/pull` - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ìƒˆ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ


**ìš”ì²­:**
```json
{
  "name": "llama2"
}
```


### 5. `/api/embeddings` - í…ìŠ¤íŠ¸ ì„ë² ë”©
ë²¡í„° ì„ë² ë”© ìƒì„±


**ìš”ì²­:**
```json
{
  "model": "llama2",
  "prompt": "Hello world"
}
```


**ì‘ë‹µ:**
```json
{
  "embedding": [0.123, -0.456, 0.789, ...]
}
```


### 6. `/api/show` - ëª¨ë¸ ì •ë³´
ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ


**ìš”ì²­:**
```json
{
  "name": "llama2"
}
```


### 7. `/api/delete` - ëª¨ë¸ ì‚­ì œ
ëª¨ë¸ ì œê±°


**ìš”ì²­:**
```json
{
  "name": "llama2"
}
```


---


## ğŸ Python ì‚¬ìš© ì˜ˆì œ


### ì„¤ì¹˜
```bash
pip install requests numpy
```


### ê°„ë‹¨í•œ ì‚¬ìš©
```python
from ollama_api_examples import OllamaClient


# í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OllamaClient("http://192.168.1.100:11434")


# 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±
result = client.generate(
    model="llama2",
    prompt="íŒŒì´ì¬ì´ë€?"
)
print(result['response'])


# 2. ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
for chunk in client.generate_stream(
    model="llama2",
    prompt="ì´ì•¼ê¸°ë¥¼ ì¨ì¤˜"
):
    print(chunk, end='', flush=True)


# 3. ì±„íŒ…
messages = [
    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}
]
result = client.chat(model="llama2", messages=messages)
print(result['message']['content'])


# 4. ëŒ€í™” ì´ì–´ê°€ê¸°
messages.append({"role": "assistant", "content": result['message']['content']})
messages.append({"role": "user", "content": "ë‚ ì”¨ ì–´ë•Œ?"})
result = client.chat(model="llama2", messages=messages)
```


### ì‹¤ìš©ì ì¸ ì˜ˆì œ


#### ğŸ“ ë²ˆì—­ê¸°
```python
def translate(text, target_lang="Korean"):
    client = OllamaClient("http://192.168.1.100:11434")
    
    prompt = f"Translate the following text to {target_lang}: {text}"
    result = client.generate(model="llama2", prompt=prompt)
    return result['response']


# ì‚¬ìš©
print(translate("Hello, how are you?", "Korean"))
```


#### ğŸ’» ì½”ë“œ ë¦¬ë·°ì–´
```python
def code_review(code):
    client = OllamaClient("http://192.168.1.100:11434")
    
    messages = [
        {"role": "system", "content": "You are an expert code reviewer."},
        {"role": "user", "content": f"Review this code:\n\n{code}"}
    ]
    
    result = client.chat(model="codellama", messages=messages)
    return result['message']['content']


# ì‚¬ìš©
code = """
def add(a, b):
    return a + b
"""
print(code_review(code))
```


#### ğŸ“š ë¬¸ì„œ ìš”ì•½ê¸°
```python
def summarize(text):
    client = OllamaClient("http://192.168.1.100:11434")
    
    prompt = f"Summarize the following text in 3 sentences:\n\n{text}"
    result = client.generate(model="llama2", prompt=prompt, temperature=0.3)
    return result['response']
```


#### ğŸ¤– ì±—ë´‡ í´ë˜ìŠ¤
```python
class Chatbot:
    def __init__(self, model="llama2", system_prompt=None):
        self.client = OllamaClient("http://192.168.1.100:11434")
        self.model = model
        self.messages = []
        
        if system_prompt:
            self.messages.append({"role": "system", "content": system_prompt})
    
    def chat(self, user_message):
        self.messages.append({"role": "user", "content": user_message})
        
        result = self.client.chat(
            model=self.model,
            messages=self.messages
        )
        
        assistant_message = result['message']['content']
        self.messages.append({"role": "assistant", "content": assistant_message})
        
        return assistant_message
    
    def reset(self):
        self.messages = []


# ì‚¬ìš©
bot = Chatbot(system_prompt="You are a friendly assistant.")
print(bot.chat("ì•ˆë…•í•˜ì„¸ìš”"))
print(bot.chat("íŒŒì´ì¬ì— ëŒ€í•´ ì•Œë ¤ì¤˜"))
```


---


## ğŸŒ cURL ì‚¬ìš© ì˜ˆì œ


### 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±
```bash
curl http://192.168.1.100:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Why is the sky blue?"
}'
```


### 2. ìŠ¤íŠ¸ë¦¬ë°
```bash
curl http://192.168.1.100:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Tell me a story",
  "stream": true
}'
```


### 3. ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨
```bash
curl http://192.168.1.100:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Write a poem",
  "system": "You are a creative poet."
}'
```


### 4. ì±„íŒ…
```bash
curl http://192.168.1.100:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ]
}'
```


### 5. ì˜µì…˜ í¬í•¨
```bash
curl http://192.168.1.100:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Write a short story",
  "options": {
    "temperature": 0.9,
    "num_predict": 200
  }
}'
```


### 6. ëª¨ë¸ ëª©ë¡
```bash
curl http://192.168.1.100:11434/api/tags
```


### 7. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
curl http://192.168.1.100:11434/api/pull -d '{
  "name": "mistral"
}'
```


### 8. ì„ë² ë”©
```bash
curl http://192.168.1.100:11434/api/embeddings -d '{
  "model": "llama2",
  "prompt": "Hello world"
}'
```


---


## âš™ï¸ ê³ ê¸‰ ì˜µì…˜


### ì˜µì…˜ íŒŒë¼ë¯¸í„°


| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¸°ë³¸ê°’ | ë²”ìœ„ |
|---------|------|--------|------|
| `temperature` | ì°½ì˜ì„± ì¡°ì ˆ (ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ) | 0.8 | 0.0 ~ 1.0 |
| `top_p` | Nucleus sampling | 0.9 | 0.0 ~ 1.0 |
| `top_k` | Top-K sampling | 40 | 1 ~ 100 |
| `num_predict` | ìµœëŒ€ ìƒì„± í† í° ìˆ˜ | 128 | 1 ~ 2048 |
| `repeat_penalty` | ë°˜ë³µ íŒ¨ë„í‹° | 1.1 | 0.0 ~ 2.0 |
| `stop` | ì¤‘ë‹¨ ë¬¸ìì—´ | [] | ë¬¸ìì—´ ë°°ì—´ |


### ì‚¬ìš© ì˜ˆì œ
```python
client.generate(
    model="llama2",
    prompt="ì´ì•¼ê¸°ë¥¼ ì¨ì¤˜",
    temperature=0.9,      # ì°½ì˜ì 
    max_tokens=500,       # ê¸¸ê²Œ
)


client.generate(
    model="codellama",
    prompt="ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜",
    temperature=0.2,      # ì •í™•í•˜ê²Œ
    max_tokens=200,
)
```


### Temperature ê°€ì´ë“œ
- **0.0 ~ 0.3**: ì •í™•ì„± ì¤‘ì‹œ (ì½”ë“œ, ë²ˆì—­, ìš”ì•½)
- **0.4 ~ 0.7**: ê· í˜•ì¡íŒ (ì¼ë°˜ì ì¸ ëŒ€í™”)
- **0.8 ~ 1.0**: ì°½ì˜ì„± ì¤‘ì‹œ (ìŠ¤í† ë¦¬, ì‹œ, ì•„ì´ë””ì–´)


---


## ğŸ”§ ì‹¤ì „ í™œìš© ì˜ˆì œ


### 1. ë°°ì¹˜ ì²˜ë¦¬
```python
def batch_process(prompts):
    client = OllamaClient("http://192.168.1.100:11434")
    results = []
    
    for prompt in prompts:
        result = client.generate(model="llama2", prompt=prompt)
        results.append(result['response'])
    
    return results


prompts = [
    "íŒŒì´ì¬ì´ë€?",
    "ìë°”ìŠ¤í¬ë¦½íŠ¸ë€?",
    "Goì–¸ì–´ë€?"
]
answers = batch_process(prompts)
```


### 2. íŒŒì¼ ì²˜ë¦¬
```python
def process_file(file_path):
    client = OllamaClient("http://192.168.1.100:11434")
    
    with open(file_path, 'r') as f:
        content = f.read()
    
    prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜:\n\n{content}"
    result = client.generate(model="llama2", prompt=prompt)
    
    return result['response']
```


### 3. ì›¹ API ì„œë²„ (Flask)
```python
from flask import Flask, request, jsonify
from ollama_api_examples import OllamaClient


app = Flask(__name__)
client = OllamaClient("http://localhost:11434")


@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_message = data.get('message')
    
    result = client.generate(
        model="llama2",
        prompt=user_message
    )
    
    return jsonify({
        'response': result['response']
    })


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```


---


## ğŸ“Œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸


| ëª¨ë¸ | ìš©ë„ | í¬ê¸° |
|------|------|------|
| `llama2` | ì¼ë°˜ ëŒ€í™”, í…ìŠ¤íŠ¸ ìƒì„± | ~4GB |
| `mistral` | ë¹ ë¥¸ ì‘ë‹µ, íš¨ìœ¨ì  | ~4GB |
| `codellama` | ì½”ë“œ ìƒì„±, ë¦¬ë·° | ~4GB |
| `llama2:13b` | ê³ í’ˆì§ˆ ì‘ë‹µ | ~7GB |
| `gemma` | Google ëª¨ë¸ | ~2GB |


### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
curl http://localhost:11434/api/pull -d '{"name": "llama2"}'
curl http://localhost:11434/api/pull -d '{"name": "mistral"}'
curl http://localhost:11434/api/pull -d '{"name": "codellama"}'
```


---


## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…


### ì—°ê²° ì˜¤ë¥˜
```python
# ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
curl http://192.168.1.100:11434/api/tags


# Pythonì—ì„œ ì—°ê²° í™•ì¸
try:
    client = OllamaClient("http://192.168.1.100:11434")
    models = client.list_models()
    print(f"ì—°ê²° ì„±ê³µ! ëª¨ë¸ ìˆ˜: {len(models)}")
except Exception as e:
    print(f"ì—°ê²° ì‹¤íŒ¨: {e}")
```


### íƒ€ì„ì•„ì›ƒ
```python
import requests


# íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ)
response = requests.post(
    "http://192.168.1.100:11434/api/generate",
    json={"model": "llama2", "prompt": "Hi"},
    timeout=60  # 60ì´ˆ
)
```


### ë©”ëª¨ë¦¬ ë¶€ì¡±
ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ 8GB ì´ìƒì˜ RAM í•„ìš”
- ì‘ì€ ëª¨ë¸ ì‚¬ìš©: `mistral`, `gemma`
- í° ëª¨ë¸ì€ GPU ê¶Œì¥


---


## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤


- [Ollama ê³µì‹ ë¬¸ì„œ](https://ollama.ai/docs)
- [API ë ˆí¼ëŸ°ìŠ¤](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬](https://ollama.ai/library)


---


## ğŸ’¡ íŒ


1. **ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©**: ê¸´ ì‘ë‹µì€ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ ì¶œë ¥
2. **Temperature ì¡°ì ˆ**: ì‘ì—…ì— ë§ê²Œ ì°½ì˜ì„± ì¡°ì ˆ
3. **ì‹œìŠ¤í…œ ë©”ì‹œì§€**: ì—­í•  ì§€ì •ìœ¼ë¡œ ë” ë‚˜ì€ ì‘ë‹µ
4. **ëŒ€í™” íˆìŠ¤í† ë¦¬**: ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
5. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ìš”ì²­ì€ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬

